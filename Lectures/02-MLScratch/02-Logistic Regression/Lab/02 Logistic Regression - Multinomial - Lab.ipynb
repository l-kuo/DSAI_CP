{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "simple-donor",
   "metadata": {},
   "source": [
    "### === Task ===\n",
    "\n",
    "1. With the iris data given in class, implement train_test_split from scratch.\n",
    "\n",
    "2. Put everything into a class called LogisticRegression, this class should allow you choose any of the training methods you'd like including \"batch\", \"minibatch\" and \"sto\". However, if the input method is not one of the three, it should \"raise ValueError\".\n",
    "\n",
    "3. Calculate time taken to fit your models using different training methods.\n",
    "\n",
    "4. Perform a classification on the dataset using all 3 methods and also show what happens if your defined training method is not either \"batch\", \"minibatch\" or \"sto\". Make sure to plot the training losses.\n",
    "\n",
    "5. Simply, use classification_report from sklearn.metrics to evaluate your models.\n",
    "\n",
    "6. Discuss your results ie. training losses of the three methods and time taken to fit models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "962d4526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2165831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "iris = datasets.load_iris()\n",
    "# print(iris.keys())\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "70a3b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4ff01b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0]\n",
    "assert X_test.shape[0] == y_test.shape[0]\n",
    "\n",
    "# add intercept\n",
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "X_train = np.concatenate((intercept, X_train), axis = 1)\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "X_test = np.concatenate((intercept, X_test), axis = 1)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "\n",
    "# define number of classes\n",
    "k = len(np.unique(y))\n",
    "# print(k)\n",
    "\n",
    "# define number of samples\n",
    "m = X_train.shape[0]\n",
    "n = X_train.shape[1]\n",
    "\n",
    "y_train_encoded = np.zeros((m,k))\n",
    "for each_class in range (k):\n",
    "    cond = y_train == each_class\n",
    "    y_train_encoded [np.where(cond), each_class] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb033835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def softmax(x):\n",
    "        return np.exp(x) / np.sum(np.exp(x), axis = 1, keepdims = True)\n",
    "    \n",
    "    def softmax_grad(X, error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
