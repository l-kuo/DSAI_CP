{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the Gradient Boosting scratch code in our lecture such that:\n",
    "- Notice that we are still using max_depth = 1.  Attempt to tweak min_samples_split, max_depth for the regression and see whether we can achieve better mse on our boston data\n",
    "- Notice that we only write scratch code for gradient boosting for regression, add some code so that it also works for binary classification.  Load the breast cancer data from sklearn and see that it works.\n",
    "- Further change the code so that it works for multiclass classification.  Load the digits data from sklearn and see that it works\n",
    "- Put everything into class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting:\n",
    "\n",
    "    \n",
    "    def __init__ (self, method = 'regression', S=5, alpha = 0.1, max_depth = 1, min_samples_split = 2):\n",
    "        self.S = S\n",
    "        self.alpha = alpha\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "#         self.regression = regression\n",
    "        self.method = method\n",
    "        \n",
    "        tree_params = {'max_depth' : self.max_depth, 'min_samples_split' : self.min_samples_split}\n",
    "        self.models = [DecisionTreeRegressor(**tree_params) for _ in range(S)]\n",
    "        first_model = DummyRegressor(strategy= 'mean')\n",
    "        self.models.insert(0, first_model)\n",
    "        \n",
    "\n",
    "    def residual(self, y, h):\n",
    "        return (y - h)  \n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.models[0].fit(X, y)\n",
    "        \n",
    "        for i in range(self.S):\n",
    "            y_hat = self.predict(X, self.models[:i+1], with_argmax = False)\n",
    "#             print(y_hat)\n",
    "            \n",
    "            gradient = self.residual(y, y_hat)       \n",
    "            self.models[i+1].fit(X, gradient)\n",
    "#             print('gradient: ', gradient)\n",
    "        \n",
    "    def predict(self, X, models = None, with_argmax = True):\n",
    "        if models is None:\n",
    "            models = self.models\n",
    "        h0 = models[0].predict(X)\n",
    "        boosting = sum(self.alpha * model.predict(X) for model in models[1:])\n",
    "        y_hat = h0 + boosting\n",
    "        \n",
    "        if self.method == 'binary' or self.method == 'multiclass':\n",
    "            y_hat = np.exp(y_hat)/ np.sum(np.exp(y_hat), axis = 1, keepdims = True)\n",
    "            if with_argmax:\n",
    "                y_hat = np.argmax(y_hat, axis = 1)\n",
    "        elif self.method != 'binary' and self.method != 'multiclass' and self.method != 'regression':\n",
    "            raise ValueError ('Please choose method between \"binary\", \"multiclass\" and \"regression\"! ')\n",
    "        return y_hat     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = load_boston(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354, 13)\n",
      "(152, 13)\n",
      "(354,)\n",
      "(152,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  7.280103220453387\n",
      "Sklearn MSE:  7.687009933213661\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "model = GradientBoosting(method = 'regression', S = 200, alpha= 0.1, max_depth= 3, min_samples_split= 3)\n",
    "model.fit(X_train, y_train)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print(\"MSE: \", mean_squared_error(y_test, y_hat))\n",
    "\n",
    "n_estimators = 200\n",
    "\n",
    "#=====SKlearn========\n",
    "#Compare to sklearn: ls is the same as our mse\n",
    "sklearn_model = GradientBoostingRegressor(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate = 0.1,\n",
    "    max_depth=3,\n",
    "    loss='ls'\n",
    ")\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn MSE: \", mean_squared_error(y_test, yhat_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y = True)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy:  0.9649122807017544\n",
      "Sklearn accuracy:  0.9649122807017544\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "for each_class in range(len(set(y))):\n",
    "    cond = y_train==each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1\n",
    "\n",
    "model = GradientBoosting(method = 'binary', S=200, alpha=0.1, max_depth = 3, min_samples_split = 3)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "print(\"Our accuracy: \", accuracy_score(y_test, y_hat))\n",
    "\n",
    "\n",
    "#=====SKlearn========\n",
    "#Compare to sklearn: ls is the same as our accuracy\n",
    "sklearn_model = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate = 0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn accuracy: \", accuracy_score(y_test, yhat_sk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy:  0.924074074074074\n",
      "Sklearn accuracy:  0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X, y = load_digits(return_X_y=True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "y_train_encoded = np.zeros((y_train.shape[0], len(set(y))))\n",
    "for each_class in range(len(set(y))):\n",
    "    cond = y_train==each_class\n",
    "    y_train_encoded[np.where(cond), each_class] = 1\n",
    "\n",
    "model = GradientBoosting(method = 'multiclass', S=200, alpha=0.1, max_depth = 3, min_samples_split = 3)\n",
    "model.fit(X_train, y_train_encoded)\n",
    "y_hat = model.predict(X_test)\n",
    "\n",
    "# #print metrics\n",
    "print(\"Our accuracy: \", accuracy_score(y_test, y_hat))\n",
    "\n",
    "#=====SKlearn========\n",
    "#Compare to sklearn: ls is the same as our accuracy\n",
    "sklearn_model = GradientBoostingClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    learning_rate = 0.1,\n",
    "    max_depth=3\n",
    ")\n",
    "\n",
    "yhat_sk = sklearn_model.fit(X_train, y_train).predict(X_test)\n",
    "print(\"Sklearn accuracy: \", accuracy_score(y_test, yhat_sk))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
